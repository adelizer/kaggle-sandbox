{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6369df0a-9195-485e-9f40-ce1fdc97b095",
   "metadata": {},
   "source": [
    "# Querying"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c350d267-981a-4abd-bb11-5983581bbfc4",
   "metadata": {},
   "source": [
    "3 main steps for querying\n",
    "\n",
    "1. retrieveing the relevant nodes\n",
    "2. post-processing: filtering on keywords or similarity scores\n",
    "3. response synthesis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8a95778a-6159-4192-98b1-a112a994e28b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import StorageContext, load_index_from_storage\n",
    "from llama_index.core import VectorStoreIndex\n",
    "from llama_index.core.schema import MetadataMode\n",
    "from llama_index.llms.openai import OpenAI\n",
    "\n",
    "storage_context = StorageContext.from_defaults(persist_dir=\"./storage\")\n",
    "index = load_index_from_storage(storage_context=storage_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6b1fa01e-e411-4fd6-8da9-1131c8728ad5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'f9b3bf49-8018-41ac-9313-6cfc18491216': RefDocInfo(node_ids=['642e947c-4c86-48c6-956a-15fa83b7ac35', '10c9a4d3-2a1b-4fae-bc55-b31082c70aa6', 'b4721a92-cd08-44fc-8e3a-f137d037676d', 'd03763d2-7b94-4032-9321-11a8283cfe25', '7aea43e9-d7db-4d46-898c-c233b3954ce4', 'b994bc38-0b36-4ad5-b1d4-92690462a19b', '9735c4ac-0c08-4d7f-9d2d-32d26892290c', 'c15d950d-0527-4c10-a314-258ec3412740', '4e44d91c-d20b-4caf-8e06-2d28c647fa1d', '98e89a5e-219e-4020-a823-d848dafc5084', '1eb28048-bcab-45fd-8b44-bf75d6beb190', '5ce487d1-f359-4ad6-9884-5a8f908e88b3', '9b49fc59-1679-44d7-b76f-ee6490ef2ff7', '5e07f79e-1d90-445a-9234-34ec5740e1e0', '8498d5fb-093d-436c-ad2b-b6a47d86240a', 'c7f8260f-2d0a-42dd-8b3b-ea365c0ac647', '3e9d169f-e301-486e-8fa1-ce30ccd12d95', '928b1455-9f8d-4a1f-925d-19faa903685c', '1bea3f2d-5011-4f6a-8b8e-71bd2ed805d8', '29526681-8568-4743-b56c-6266f96bc337', '252bbb52-1328-46b1-ad74-b62968484fd1', '43528ae4-90f2-442f-a5f3-37a81c604c3b'], metadata={'file_path': '/Users/mohamedadelabdelhady/workspace/kaggle-sandbox/llm-playground/data/paul_graham_essay.txt', 'file_name': 'paul_graham_essay.txt', 'file_type': 'text/plain', 'file_size': 75041, 'creation_date': '2024-05-03', 'last_modified_date': '2024-05-02'})}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index.ref_doc_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "0358c5d3-2de0-4049-89cb-8a60d6968c26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v = index.ref_doc_info.values()\n",
    "len(list(v)[0].to_dict()[\"node_ids\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3f3403d9-14f0-4971-8df6-928b4d3be3ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_engine = index.as_query_engine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2966b329-7357-4629-a78c-81627d07fbd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The author studied in a PhD program in computer science and later attended RISD (Rhode Island School of Design) for the BFA program.\n"
     ]
    }
   ],
   "source": [
    "response = query_engine.query(\"Where did the author study?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "fb53d9bd-2788-450b-908a-adf5fe29ad41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(response.source_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "1824afc2-5108-4621-a4e8-6e0030e4ee64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node ID: d03763d2-7b94-4032-9321-11a8283cfe25\n",
      "Text: If he even knew about the strange classes I was taking, he never\n",
      "said anything.  So now I was in a PhD program in computer science, yet\n",
      "planning to be an artist, yet also genuinely in love with Lisp hacking\n",
      "and working away at On Lisp. In other words, like many a grad student,\n",
      "I was working energetically on multiple projects that were not my\n",
      "the...\n",
      "Score:  0.835\n",
      "\n",
      "Node ID: 642e947c-4c86-48c6-956a-15fa83b7ac35\n",
      "Text: What I Worked On  February 2021  Before college the two main\n",
      "things I worked on, outside of school, were writing and programming. I\n",
      "didn't write essays. I wrote what beginning writers were supposed to\n",
      "write then, and probably still are: short stories. My stories were\n",
      "awful. They had hardly any plot, just characters with strong feelings,\n",
      "which I ...\n",
      "Score:  0.822\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for n in response.source_nodes:\n",
    "    print(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b30fb9fc-d4a9-4f52-8931-a281abdcdab6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'response_synthesizer:text_qa_template': SelectorPromptTemplate(metadata={'prompt_type': <PromptType.QUESTION_ANSWER: 'text_qa'>}, template_vars=['context_str', 'query_str'], kwargs={}, output_parser=None, template_var_mappings={}, function_mappings={}, default_template=PromptTemplate(metadata={'prompt_type': <PromptType.QUESTION_ANSWER: 'text_qa'>}, template_vars=['context_str', 'query_str'], kwargs={}, output_parser=None, template_var_mappings=None, function_mappings=None, template='Context information is below.\\n---------------------\\n{context_str}\\n---------------------\\nGiven the context information and not prior knowledge, answer the query.\\nQuery: {query_str}\\nAnswer: '), conditionals=[(<function is_chat_model at 0x127420160>, ChatPromptTemplate(metadata={'prompt_type': <PromptType.CUSTOM: 'custom'>}, template_vars=['context_str', 'query_str'], kwargs={}, output_parser=None, template_var_mappings=None, function_mappings=None, message_templates=[ChatMessage(role=<MessageRole.SYSTEM: 'system'>, content=\"You are an expert Q&A system that is trusted around the world.\\nAlways answer the query using the provided context information, and not prior knowledge.\\nSome rules to follow:\\n1. Never directly reference the given context in your answer.\\n2. Avoid statements like 'Based on the context, ...' or 'The context information ...' or anything along those lines.\", additional_kwargs={}), ChatMessage(role=<MessageRole.USER: 'user'>, content='Context information is below.\\n---------------------\\n{context_str}\\n---------------------\\nGiven the context information and not prior knowledge, answer the query.\\nQuery: {query_str}\\nAnswer: ', additional_kwargs={})]))]),\n",
       " 'response_synthesizer:refine_template': SelectorPromptTemplate(metadata={'prompt_type': <PromptType.REFINE: 'refine'>}, template_vars=['query_str', 'existing_answer', 'context_msg'], kwargs={}, output_parser=None, template_var_mappings={}, function_mappings={}, default_template=PromptTemplate(metadata={'prompt_type': <PromptType.REFINE: 'refine'>}, template_vars=['query_str', 'existing_answer', 'context_msg'], kwargs={}, output_parser=None, template_var_mappings=None, function_mappings=None, template=\"The original query is as follows: {query_str}\\nWe have provided an existing answer: {existing_answer}\\nWe have the opportunity to refine the existing answer (only if needed) with some more context below.\\n------------\\n{context_msg}\\n------------\\nGiven the new context, refine the original answer to better answer the query. If the context isn't useful, return the original answer.\\nRefined Answer: \"), conditionals=[(<function is_chat_model at 0x127420160>, ChatPromptTemplate(metadata={'prompt_type': <PromptType.CUSTOM: 'custom'>}, template_vars=['context_msg', 'query_str', 'existing_answer'], kwargs={}, output_parser=None, template_var_mappings=None, function_mappings=None, message_templates=[ChatMessage(role=<MessageRole.USER: 'user'>, content=\"You are an expert Q&A system that strictly operates in two modes when refining existing answers:\\n1. **Rewrite** an original answer using the new context.\\n2. **Repeat** the original answer if the new context isn't useful.\\nNever reference the original answer or context directly in your answer.\\nWhen in doubt, just repeat the original answer.\\nNew Context: {context_msg}\\nQuery: {query_str}\\nOriginal Answer: {existing_answer}\\nNew Answer: \", additional_kwargs={})]))])}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_engine.get_prompts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "760d5090-96e0-4c60-92f9-7c15c0896960",
   "metadata": {},
   "source": [
    "### Custom stages\n",
    "\n",
    "instead of calling index.as_query_engine() you can also define the query engine more explicitly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "40bacdd4-4386-4fba-853a-017e515e030c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import VectorStoreIndex, get_response_synthesizer, StorageContext, load_index_from_storage\n",
    "from llama_index.core.retrievers import VectorIndexRetriever\n",
    "from llama_index.core.query_engine import RetrieverQueryEngine\n",
    "from llama_index.core.postprocessor import SimilarityPostprocessor, KeywordNodePostprocessor\n",
    "from llama_index.core.response_synthesizers import ResponseMode\n",
    "\n",
    "storage_context = StorageContext.from_defaults(persist_dir=\"./storage\")\n",
    "index = load_index_from_storage(storage_context)\n",
    "\n",
    "retriever = VectorIndexRetriever(index=index, similarity_top_k=5)\n",
    "response_synthesizer = get_response_synthesizer(response_mode=ResponseMode.NO_TEXT)\n",
    "\n",
    "# assemble the query engine\n",
    "query_engine = RetrieverQueryEngine(retriever=retriever, response_synthesizer=response_synthesizer, node_postprocessors=[SimilarityPostprocessor(similarity_cutoff=0.821)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "92e8ae55-cdb8-4bc7-9ea6-ac95d45d0582",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "response = query_engine.query(\"Where did the author study?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "b5dd8ba3-5675-4012-a66e-21472bde0fcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node ID: d03763d2-7b94-4032-9321-11a8283cfe25\n",
      "Text: If he even knew about the strange classes I was taking, he never\n",
      "said anything.  So now I was in a PhD program in computer science, yet\n",
      "planning to be an artist, yet also genuinely in love with Lisp hacking\n",
      "and working away at On Lisp. In other words, like many a grad student,\n",
      "I was working energetically on multiple projects that were not my\n",
      "the...\n",
      "Score:  0.835\n",
      "\n",
      "Node ID: 642e947c-4c86-48c6-956a-15fa83b7ac35\n",
      "Text: What I Worked On  February 2021  Before college the two main\n",
      "things I worked on, outside of school, were writing and programming. I\n",
      "didn't write essays. I wrote what beginning writers were supposed to\n",
      "write then, and probably still are: short stories. My stories were\n",
      "awful. They had hardly any plot, just characters with strong feelings,\n",
      "which I ...\n",
      "Score:  0.822\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for n in response.source_nodes:\n",
    "    print(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "e8c7dd48-14d7-445c-a0a3-d548d452850e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'file_path': '/Users/mohamedadelabdelhady/workspace/kaggle-sandbox/llm-playground/data/paul_graham_essay.txt',\n",
       " 'file_name': 'paul_graham_essay.txt',\n",
       " 'file_type': 'text/plain',\n",
       " 'file_size': 75041,\n",
       " 'creation_date': '2024-05-03',\n",
       " 'last_modified_date': '2024-05-02'}"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n.metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0563c0d-60af-48fa-a4a2-19b9279c6027",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
