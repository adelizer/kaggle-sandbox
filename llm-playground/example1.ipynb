{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3a7972fb-369f-4256-8dc6-b65d44aacd94",
   "metadata": {},
   "source": [
    "# Example 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6596fa6f-3339-4e72-93f2-8c4a94d5950c",
   "metadata": {},
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "92377036-5882-407e-871f-731ef7918678",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ingest documents from multiple sources \n",
    "import uuid\n",
    "from llama_index.core import Document, SimpleDirectoryReader\n",
    "from llama_index.readers.web import SimpleWebPageReader\n",
    "\n",
    "documents = SimpleDirectoryReader(\"./data\").load_data()\n",
    "documents += [Document(text=\"The simplest way to store your indexed data is to use the built-in .persist() method of every Index, which writes all the data to disk at the location specified. This works for any type of index.\",\n",
    "                      doc_id=str(uuid.uuid4()),\n",
    "                      metadata={\"foo\": \"bar\", \"category\": \"documentation\"}, # metadata will propagate to the nodes\n",
    "                      excluded_llm_metadata_keys=[\"foo\"] # some keys could be excluded from the text_content()\n",
    "                      )]\n",
    "documents += SimpleWebPageReader(html_to_text=True).load_data(urls=[\"https://docs.pinecone.io/home\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d94701d4-cd57-4a35-b095-f4b5ff91336d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "0195671a-c482-412d-9a44-28b5d59a8858",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(id_='https://docs.pinecone.io/home', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, text='[Pinecone Docs home page![light logo](https://mintlify.s3-us-\\nwest-1.amazonaws.com/pinecone-2/logo/light.png)![dark\\nlogo](https://mintlify.s3-us-\\nwest-1.amazonaws.com/pinecone-2/logo/dark.png)](/)\\n\\nLatest\\n\\nSearch or ask...\\n\\n  * [Sign up free](https://app.pinecone.io/?sessionType=signup)\\n  * [Status](https://status.pinecone.io)\\n  * [Support](https://support.pinecone.io)\\n  * [Log In](https://app.pinecone.io/?sessionType=login)\\n  * [Sign up free](https://app.pinecone.io/?sessionType=signup)\\n\\nSearch\\n\\nNavigation\\n\\n[Home](/)[Guides](/guides/get-\\nstarted/quickstart)[Reference](/reference/api/introduction)[Examples](/examples/notebooks)[Integrations](/integrations/overview)[Tools](/tools/pinecone-\\nutilities)[Troubleshooting](/troubleshooting/contact-\\nsupport)[Releases](/release-notes/2024)\\n\\n![](https://mintlify.s3-us-\\nwest-1.amazonaws.com/pinecone-2/images/background.png)\\n\\nPinecone Documentation\\n\\nWhat can we help you build?\\n\\nStart a chat with us…\\n\\nChoose a topic below or simply [get started](/guides/get-started/quickstart)\\n\\n[\\n\\n## Guides\\n\\nPractical guides and best practices to get you up and running quickly.\\n\\n](/guides)[\\n\\n## Reference\\n\\nComprehensive details about the Pinecone API, SDKs, and architecture.\\n\\n](/reference)[\\n\\n## Examples\\n\\nHands-on notebooks and sample apps with common AI patterns and tools.\\n\\n](/examples)[\\n\\n## Integrations\\n\\nPinecone’s growing number of third-party integrations.\\n\\n](/integrations)[\\n\\n## Tools\\n\\nCode and docs for Pinecone utilities and reference architectures.\\n\\n](/tools)[\\n\\n## Troubleshooting\\n\\nResolve common Pinecone issues with our troubleshooting guide.\\n\\n](/troubleshooting/contact-support)[\\n\\n## Releases\\n\\nNews about features and changes in Pinecone and related tools.\\n\\n](/release-notes)\\n\\n', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n')"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83c2b171-903f-4078-9df5-4902f3ac274e",
   "metadata": {},
   "source": [
    "### Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bf25072e-82f8-452f-8803-7d098a557645",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24\n"
     ]
    }
   ],
   "source": [
    "# Creating nodes/chunks \n",
    "from llama_index.core.node_parser import SimpleNodeParser, SentenceSplitter, TokenTextSplitter, TextSplitter\n",
    "from llama_index.core.ingestion import IngestionPipeline\n",
    "\n",
    "# creating text nodes\n",
    "parser = SimpleNodeParser.from_defaults()\n",
    "nodes = parser.get_nodes_from_documents(documents)\n",
    "print(len(nodes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3b8c3876-3d7f-47aa-937b-f95b2ed7e617",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n"
     ]
    }
   ],
   "source": [
    "# using a different splitter -> this will create different number of nodes\n",
    "text_splitter = SentenceSplitter(chunk_size=1024, chunk_overlap=20)\n",
    "pipeline = IngestionPipeline(transformations=[text_splitter])\n",
    "nodes = pipeline.run(documents=documents)\n",
    "print(len(nodes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f56a59e5-4b63-4ea9-8f83-3cfc55ab3620",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[dict_keys(['file_path', 'file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date']),\n",
       " dict_keys(['file_path', 'file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date']),\n",
       " dict_keys(['file_path', 'file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date']),\n",
       " dict_keys(['file_path', 'file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date']),\n",
       " dict_keys(['file_path', 'file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date']),\n",
       " dict_keys(['file_path', 'file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date']),\n",
       " dict_keys(['file_path', 'file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date']),\n",
       " dict_keys(['file_path', 'file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date']),\n",
       " dict_keys(['file_path', 'file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date']),\n",
       " dict_keys(['file_path', 'file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date']),\n",
       " dict_keys(['file_path', 'file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date']),\n",
       " dict_keys(['file_path', 'file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date']),\n",
       " dict_keys(['file_path', 'file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date']),\n",
       " dict_keys(['file_path', 'file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date']),\n",
       " dict_keys(['file_path', 'file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date']),\n",
       " dict_keys(['file_path', 'file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date']),\n",
       " dict_keys(['file_path', 'file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date']),\n",
       " dict_keys(['file_path', 'file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date']),\n",
       " dict_keys(['foo', 'category']),\n",
       " dict_keys([])]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[n.metadata.keys() for n in nodes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d5855376-6b0b-4be1-a3d6-22b69b53a23c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:01<00:00,  3.25it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  1.66it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  1.57it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:03<00:00,  5.08it/s]\n"
     ]
    }
   ],
   "source": [
    "# creating nodes with automatic metadata extraction\n",
    "# here we need to start making API requests to an LLM\n",
    "# you NEED to set the OPENAI_API_KEY env variable \n",
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()\n",
    "\n",
    "from llama_index.core.extractors import TitleExtractor, KeywordExtractor\n",
    "from llama_index.core.schema import MetadataMode\n",
    "from llama_index.llms.openai import OpenAI\n",
    "llm = OpenAI(model=\"gpt-3.5-turbo\", temperature=0.1)\n",
    "\n",
    "enrich_metadata_pipeline = IngestionPipeline(transformations=[SentenceSplitter(chunk_size=1024, chunk_overlap=20),\n",
    "                                                              TitleExtractor(llm=llm, metadata_mode=MetadataMode.EMBED),\n",
    "                                                              KeywordExtractor(llm=llm, metadata_mode=MetadataMode.EMBED),\n",
    "                                                             ])\n",
    "nodes = enrich_metadata_pipeline.run(documents=documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8ed67888-2e38-4e5c-9013-6ac97861f9e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[dict_keys(['file_path', 'file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'document_title', 'excerpt_keywords']),\n",
       " dict_keys(['file_path', 'file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'document_title', 'excerpt_keywords']),\n",
       " dict_keys(['file_path', 'file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'document_title', 'excerpt_keywords']),\n",
       " dict_keys(['file_path', 'file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'document_title', 'excerpt_keywords']),\n",
       " dict_keys(['file_path', 'file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'document_title', 'excerpt_keywords']),\n",
       " dict_keys(['file_path', 'file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'document_title', 'excerpt_keywords']),\n",
       " dict_keys(['file_path', 'file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'document_title', 'excerpt_keywords']),\n",
       " dict_keys(['file_path', 'file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'document_title', 'excerpt_keywords']),\n",
       " dict_keys(['file_path', 'file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'document_title', 'excerpt_keywords']),\n",
       " dict_keys(['file_path', 'file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'document_title', 'excerpt_keywords']),\n",
       " dict_keys(['file_path', 'file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'document_title', 'excerpt_keywords']),\n",
       " dict_keys(['file_path', 'file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'document_title', 'excerpt_keywords']),\n",
       " dict_keys(['file_path', 'file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'document_title', 'excerpt_keywords']),\n",
       " dict_keys(['file_path', 'file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'document_title', 'excerpt_keywords']),\n",
       " dict_keys(['file_path', 'file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'document_title', 'excerpt_keywords']),\n",
       " dict_keys(['file_path', 'file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'document_title', 'excerpt_keywords']),\n",
       " dict_keys(['file_path', 'file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'document_title', 'excerpt_keywords']),\n",
       " dict_keys(['file_path', 'file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'document_title', 'excerpt_keywords']),\n",
       " dict_keys(['foo', 'category', 'document_title', 'excerpt_keywords']),\n",
       " dict_keys(['document_title', 'excerpt_keywords'])]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[n.metadata.keys() for n in nodes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "990a274e-fcc0-45f9-831c-28b73635ee46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['writing, programming, philosophy, art, language learning',\n",
       " 'AI, Lisp, SHRDLU, Artificial Intelligence, Programming',\n",
       " 'exploration, programming, art, philosophy, language learning',\n",
       " 'painting, art, learning, language, exploration',\n",
       " 'Paul Graham, Interleaf, Lisp, RISD, Art School',\n",
       " 'painting, signature style, New York, World Wide Web, art galleries',\n",
       " 'art galleries, online stores, web app, Viaweb, WYSIWYG site builder',\n",
       " 'software, programming, ecommerce, retail, Viaweb',\n",
       " 'startup growth, internet bubble, Viaweb, Yahoo acquisition, painting',\n",
       " 'painting, New York, web apps, Lisp, software as a service',\n",
       " 'Exploration, Programming, Philosophy, Art, Language Learning',\n",
       " 'spam filters, painting, startup founders, angel investing, Y Combinator',\n",
       " 'startups, Y Combinator, batch model, funding, community',\n",
       " 'writing, programming, philosophy, art, language learning',\n",
       " 'writing, programming, philosophy, art, language learning',\n",
       " 'Lisp, Programming Language, Bel, McCarthy, Interpreter',\n",
       " 'batch processing, microcomputers, Italian, still life painting, Y Combinator',\n",
       " 'Paul Graham, Y Combinator, startups, forum, language learning',\n",
       " 'Storing, Indexed Data, .persist() Method, Comprehensive Guide, Disk Storage',\n",
       " 'Pinecone, Documentation, Resources, Guides, Integrations']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[n.metadata[\"excerpt_keywords\"] for n in nodes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d37c2747-4525-4145-8529-180264a30ad6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "aa5ad392-9bba-496e-8d8a-9c1e982c3964",
   "metadata": {},
   "source": [
    "### Indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "884487b1-ee60-4f84-b54c-f108304828c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mohamedadelabdelhady/workspace/kaggle-sandbox/venv/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Generating embeddings: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:01<00:00, 18.43it/s]\n"
     ]
    }
   ],
   "source": [
    "from llama_index.core import VectorStoreIndex\n",
    "# On a high-level, index can be created from documents directly, this will use a default node parser\n",
    "# index = VectorStoreIndex.from_documents(documents, show_progress=True)\n",
    "\n",
    "index = VectorStoreIndex(nodes, show_progress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "859e1835-6832-45b8-b071-8ee085ef3b1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(index.index_struct.nodes_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7d92db9c-d7ab-4267-8611-02c974bff309",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'5daac5eb-7e75-44d8-aee3-c308f359d2b3': RefDocInfo(node_ids=['b7cd3755-8335-40e5-875e-b06a357ba38f', '8ebbf89f-3196-4b9f-865b-f5fde85479dc', '6c841bcb-3c1c-4189-ae34-979575c95693', '9c9bae0a-f961-47b3-96f3-5c5675b06c74', '1ee49e3d-2b90-43c5-b735-46552a9f71b8', '438ba729-223f-4ffe-bbc8-a3aabb9331b0', 'c13c2f90-42eb-4356-9b52-926376f215b6', '8a135b25-ecd0-4bbc-b907-b17722419151', '0db7e674-47a3-487c-9393-a47ad2104545', '970e3b9b-d05d-412c-8141-ba9454774491', 'df8070e7-3cec-4375-ad30-609f39907071', '494f771d-d55c-43d4-a2d7-08bfb9c471fc', '6968eafd-98af-4a6c-94ed-18a173174c0f', '34733c08-6120-412f-80f8-7cd6c1ee7488', '63d0a688-7cf1-48c2-8c12-f4c03fd71de9', '40c7ceb5-420a-4cb2-94c2-23bab804dc31', '20cc598b-a66e-44e6-927a-4a4282ce7993', 'b6b1f44b-9cf4-45ae-8985-59d21430ee0c'], metadata={'file_path': '/Users/mohamedadelabdelhady/workspace/kaggle-sandbox/llm-playground/data/paul_graham_essay.txt', 'file_name': 'paul_graham_essay.txt', 'file_type': 'text/plain', 'file_size': 75041, 'creation_date': '2024-05-03', 'last_modified_date': '2024-05-02', 'document_title': 'A Journey of Exploration: Writing, Programming, Philosophy, Art, and Language Learning', 'excerpt_keywords': 'writing, programming, philosophy, art, language learning'}),\n",
       " 'd9cf5ef1-06c3-4f09-9217-4ed120f8f681': RefDocInfo(node_ids=['335a9ddb-3a4e-410a-bde3-80143a7bea83'], metadata={'foo': 'bar', 'category': 'documentation', 'document_title': 'Storing Indexed Data with the .persist() Method: A Comprehensive Guide', 'excerpt_keywords': 'Storing, Indexed Data, .persist() Method, Comprehensive Guide, Disk Storage'}),\n",
       " 'https://docs.pinecone.io/home': RefDocInfo(node_ids=['ef41f6b7-ff90-4613-a121-f9be2f3c406e'], metadata={'document_title': '\"Pinecone Documentation and Resources: A Comprehensive Guide\"', 'excerpt_keywords': 'Pinecone, Documentation, Resources, Guides, Integrations'})}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# no direct way to show the actual vector embeddings :/\n",
    "index.ref_doc_info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33869137-e86d-4417-863f-f08f627ddfa0",
   "metadata": {},
   "source": [
    "### Storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "81e47ca5-4675-48e3-8ac9-ce6752c0835a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this will overwrite all the json files in storage\n",
    "index.storage_context.persist(persist_dir=\"./storage\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "ee21046a-1bbc-4753-b1d9-330a22bf0c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pinecone import Pinecone, ServerlessSpec\n",
    "from llama_index.core import StorageContext\n",
    "from llama_index.vector_stores.pinecone import PineconeVectorStore\n",
    "\n",
    "pc = Pinecone(\n",
    "    api_key=os.environ.get(\"PINECONE_API_KEY\")\n",
    ")\n",
    "pinecone_index = pc.Index(\"quickstart-index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "a75e610a-c44b-46b0-bc10-ea1a329cd746",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_store = PineconeVectorStore(pinecone_index=pinecone_index)\n",
    "storage_context = StorageContext.from_defaults(vector_store=vector_store)\n",
    "# index = VectorStoreIndex(nodes, storage_context=storage_context, show_progress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "8cea1a3f-9ff2-4a25-a806-5b4b5a9523e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# not sure if this works\n",
    "index.storage_context.add_vector_store(vector_store, namespace=\"default\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f8dd9ce-d804-43d3-9468-9b20f9a0081c",
   "metadata": {},
   "source": [
    "### Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "06ee32d7-e7de-4617-b501-2db6bd0ef719",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import StorageContext, load_index_from_storage\n",
    "\n",
    "storage_context = StorageContext.from_defaults(persist_dir=\"./storage\")\n",
    "index = load_index_from_storage(storage_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "bbf068d3-9160-423d-a54e-a2fb044d52e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'5daac5eb-7e75-44d8-aee3-c308f359d2b3': RefDocInfo(node_ids=['b7cd3755-8335-40e5-875e-b06a357ba38f', '8ebbf89f-3196-4b9f-865b-f5fde85479dc', '6c841bcb-3c1c-4189-ae34-979575c95693', '9c9bae0a-f961-47b3-96f3-5c5675b06c74', '1ee49e3d-2b90-43c5-b735-46552a9f71b8', '438ba729-223f-4ffe-bbc8-a3aabb9331b0', 'c13c2f90-42eb-4356-9b52-926376f215b6', '8a135b25-ecd0-4bbc-b907-b17722419151', '0db7e674-47a3-487c-9393-a47ad2104545', '970e3b9b-d05d-412c-8141-ba9454774491', 'df8070e7-3cec-4375-ad30-609f39907071', '494f771d-d55c-43d4-a2d7-08bfb9c471fc', '6968eafd-98af-4a6c-94ed-18a173174c0f', '34733c08-6120-412f-80f8-7cd6c1ee7488', '63d0a688-7cf1-48c2-8c12-f4c03fd71de9', '40c7ceb5-420a-4cb2-94c2-23bab804dc31', '20cc598b-a66e-44e6-927a-4a4282ce7993', 'b6b1f44b-9cf4-45ae-8985-59d21430ee0c'], metadata={'file_path': '/Users/mohamedadelabdelhady/workspace/kaggle-sandbox/llm-playground/data/paul_graham_essay.txt', 'file_name': 'paul_graham_essay.txt', 'file_type': 'text/plain', 'file_size': 75041, 'creation_date': '2024-05-03', 'last_modified_date': '2024-05-02', 'document_title': 'A Journey of Exploration: Writing, Programming, Philosophy, Art, and Language Learning', 'excerpt_keywords': 'writing, programming, philosophy, art, language learning'}),\n",
       " 'd9cf5ef1-06c3-4f09-9217-4ed120f8f681': RefDocInfo(node_ids=['335a9ddb-3a4e-410a-bde3-80143a7bea83'], metadata={'foo': 'bar', 'category': 'documentation', 'document_title': 'Storing Indexed Data with the .persist() Method: A Comprehensive Guide', 'excerpt_keywords': 'Storing, Indexed Data, .persist() Method, Comprehensive Guide, Disk Storage'}),\n",
       " 'https://docs.pinecone.io/home': RefDocInfo(node_ids=['ef41f6b7-ff90-4613-a121-f9be2f3c406e'], metadata={'document_title': '\"Pinecone Documentation and Resources: A Comprehensive Guide\"', 'excerpt_keywords': 'Pinecone, Documentation, Resources, Guides, Integrations'})}"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index.ref_doc_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "da6d603f-5832-4cd8-87c2-63e2ed902312",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(index.index_struct.nodes_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "980fb10f-3c19-4019-80a3-336cbd0dfd86",
   "metadata": {},
   "source": [
    "### Querying"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "cff93ef1-19ab-4de7-9184-8ddd4685ec2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import VectorStoreIndex, get_response_synthesizer, StorageContext, load_index_from_storage\n",
    "from llama_index.core.retrievers import VectorIndexRetriever\n",
    "from llama_index.core.query_engine import RetrieverQueryEngine\n",
    "from llama_index.core.postprocessor import SimilarityPostprocessor, KeywordNodePostprocessor\n",
    "from llama_index.core.response_synthesizers import ResponseMode\n",
    "from llama_index.core.response.pprint_utils import pprint_source_node\n",
    "\n",
    "storage_context = StorageContext.from_defaults(persist_dir=\"./storage\")\n",
    "index = load_index_from_storage(storage_context)\n",
    "\n",
    "retriever = VectorIndexRetriever(index=index, similarity_top_k=5)\n",
    "response_synthesizer = get_response_synthesizer(response_mode=ResponseMode.COMPACT)\n",
    "\n",
    "# assemble the query engine\n",
    "query_engine = RetrieverQueryEngine(retriever=retriever, response_synthesizer=response_synthesizer, node_postprocessors=[SimilarityPostprocessor(similarity_cutoff=0.8)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "98ca1175-45d1-4bc7-881a-481c517ed1a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paul Graham studied at Harvard University.\n"
     ]
    }
   ],
   "source": [
    "response = query_engine.query(\"Where did paul graham study?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "6472e93f-7855-4e09-a562-49edd422d601",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node ID: 6c841bcb-3c1c-4189-ae34-979575c95693\n",
      "Similarity: 0.8319346545834482\n",
      "Text: There were some surplus Xerox Dandelions floating around the\n",
      "computer lab at one point. Anyone who wanted one to play around with\n",
      "could have one. I was briefly tempted, but they were so slow by\n",
      "present standards; what was the point? No one else wanted one either,\n",
      "so off they went. That was what happened to systems work.  I wanted\n",
      "not just to bui...\n",
      "Node ID: 1ee49e3d-2b90-43c5-b735-46552a9f71b8\n",
      "Similarity: 0.8277081509817129\n",
      "Text: Our teacher, professor Ulivi, was a nice guy. He could see I\n",
      "worked hard, and gave me a good grade, which he wrote down in a sort\n",
      "of passport each student had. But the Accademia wasn't teaching me\n",
      "anything except Italian, and my money was running out, so at the end\n",
      "of the first year I went back to the US.  I wanted to go back to RISD,\n",
      "but I was ...\n",
      "Node ID: b7cd3755-8335-40e5-875e-b06a357ba38f\n",
      "Similarity: 0.8157514284606912\n",
      "Text: What I Worked On  February 2021  Before college the two main\n",
      "things I worked on, outside of school, were writing and programming. I\n",
      "didn't write essays. I wrote what beginning writers were supposed to\n",
      "write then, and probably still are: short stories. My stories were\n",
      "awful. They had hardly any plot, just characters with strong feelings,\n",
      "which I ...\n",
      "Node ID: 970e3b9b-d05d-412c-8141-ba9454774491\n",
      "Similarity: 0.813889790736965\n",
      "Text: So I tried to paint, but I just didn't seem to have any energy\n",
      "or ambition. Part of the problem was that I didn't know many people in\n",
      "California. I'd compounded this problem by buying a house up in the\n",
      "Santa Cruz Mountains, with a beautiful view but miles from anywhere. I\n",
      "stuck it out for a few more months, then in desperation I went back to\n",
      "New...\n",
      "Node ID: df8070e7-3cec-4375-ad30-609f39907071\n",
      "Similarity: 0.8110959403208846\n",
      "Text: Much to my surprise, the time I spent working on this stuff was\n",
      "not wasted after all. After we started Y Combinator, I would often\n",
      "encounter startups working on parts of this new architecture, and it\n",
      "was very useful to have spent so much time thinking about it and even\n",
      "trying to write some of it.  The subset I would build as an open\n",
      "source proje...\n"
     ]
    }
   ],
   "source": [
    "for node in response.source_nodes:\n",
    "    pprint_source_node(node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "019df92d-0705-48ef-817d-42b1200dba25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The simplest way to store indexed data is to use the built-in .persist() method of every Index, which writes all the data to disk at the location specified.\n"
     ]
    }
   ],
   "source": [
    "response = query_engine.query(\"what is the simplest way to store indexed data?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "e521bbae-9d51-4411-99a2-86df0fde146e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node ID: 335a9ddb-3a4e-410a-bde3-80143a7bea83\n",
      "Similarity: 0.8419226761880413\n",
      "Text: The simplest way to store your indexed data is to use the built-\n",
      "in .persist() method of every Index, which writes all the data to disk\n",
      "at the location specified. This works for any type of index.\n"
     ]
    }
   ],
   "source": [
    "for node in response.source_nodes:\n",
    "    pprint_source_node(node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "d8e3d624-0e22-434b-8d9e-5d47ab27319e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Pinecone Documentation and Resources provide a comprehensive guide that includes practical guides, detailed information about the Pinecone API, SDKs, and architecture, hands-on notebooks and sample apps with common AI patterns and tools, third-party integrations, Pinecone utilities and reference architectures, a troubleshooting guide to resolve common Pinecone issues, and news about features and changes in Pinecone and related tools.\n",
      "Node ID: ef41f6b7-ff90-4613-a121-f9be2f3c406e\n",
      "Similarity: 0.8953077987680225\n",
      "Text: [Pinecone Docs home page![light logo](https://mintlify.s3-us-\n",
      "west-1.amazonaws.com/pinecone-2/logo/light.png)![dark\n",
      "logo](https://mintlify.s3-us-\n",
      "west-1.amazonaws.com/pinecone-2/logo/dark.png)](/)  Latest  Search or\n",
      "ask...    * [Sign up\n",
      "free](https://app.pinecone.io/?sessionType=signup)   *\n",
      "[Status](https://status.pinecone.io)   * [Support](http...\n"
     ]
    }
   ],
   "source": [
    "response = query_engine.query(\"Pinecone Documentation and Resources: A Comprehensive Guide\")\n",
    "print(response)\n",
    "for node in response.source_nodes:\n",
    "    pprint_source_node(node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "e35dc151-263b-40ee-ad95-22d2608e99c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<llama_index.core.indices.vector_store.base.VectorStoreIndex at 0x168f25910>"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
